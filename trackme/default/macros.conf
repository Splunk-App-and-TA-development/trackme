# macros.conf

# comment
[comment(1)]
args = text
definition = ""
iseval = 1

# For Splunk 7.3.x and later, you might want to include include_reduced_buckets=t
[tstats]
definition = tstats
iseval = 0

# trackMe summary index, customise its value to use your own index naming convention, default to summary
[trackme_idx]
definition = index="summary"
iseval = 0

# Data source availability default monitored state
# customize this macro to change the way the monitored state is defined by default, such as conditional operations
# using the index or sourcetype naming convention

# used as the top of the populating searches
[trackme_tstats_main_filter]
definition = sourcetype!="stash" sourcetype!="*too_small"
iseval = 0

# used as the top of the populating searches for metric indexes
[trackme_mstats_main_filter]
definition = metric_name="*"
iseval = 0

[trackme_default_monitored_state]
definition = eval data_monitored_state=if(isnull(data_monitored_state), "enabled", data_monitored_state)
iseval = 0

[trackme_default_host_monitored_state]
definition = eval data_monitored_state=if(isnull(data_monitored_state), "enabled", data_monitored_state)
iseval = 0

[trackme_default_metric_host_monitored_state]
definition = eval metric_monitored_state=if(isnull(metric_monitored_state), "enabled", metric_monitored_state)
iseval = 0

[trackme_default_lag]
definition = eval data_max_lag_allowed=if(isnull(data_max_lag_allowed), "3600", data_max_lag_allowed)
iseval = 0

[trackme_default_host_lag]
definition = eval data_max_lag_allowed=if(isnull(data_max_lag_allowed), "86400", data_max_lag_allowed)
iseval = 0

[trackme_default_metric_host_lag]
definition = eval metric_max_lag_allowed=if(isnull(metric_max_lag_allowed), "300", metric_max_lag_allowed)
iseval = 0

[trackme_default_monitored_wdays]
definition = eval data_monitoring_wdays=if(isnull(data_monitoring_wdays), "auto:all_days", data_monitoring_wdays)
iseval = 0

[trackme_default_host_monitored_wdays]
definition = eval data_monitoring_wdays=if(isnull(data_monitoring_wdays), "auto:all_days", data_monitoring_wdays)
iseval = 0

[trackme_default_priority]
definition = eval priority=if(isnull(priority), "medium", priority)

# can be customized for filtering
[trackme_data_sources_filtering]
definition = search data_name=*
iseval = 0

# can be customized for date format
[trackme_date_format(1)]
args = input_field
definition = eval "$input_field$ (translated)"=strftime($input_field$, "%d/%m/%Y %H:%M")
iseval = 0

# defined pattern filter for indexers
[trackme_idx_filter]
definition = host=idx*
iseval = 0

# define the tolerance in negative seconds regarding the detection of data indexed in the future (default 30 seconds)
[trackme_future_indexing_tolerance]
definition = -600
iseval = 0

# define a filtering rule for host names, sometimes complex ingestion method that requires host Meta overwrite can fail which results in pollution of wrong hosts
# A host should match a traditional naming convention
# By default: alphanumeric chars, literal dots and hyphens, less than 100 chars
[trackme_data_host_rule_filter(1)]
args = key
definition = where match($key$, "[\w|\-|\.]") AND len($key$)<100
iseval = 0

# Evaluate the icon fields rendering
[trackme_eval_icons]
definition = fillnull value="NA" "data_last_time_seen (translated)", data_last_lag_seen, data_max_lag_allowed, data_last_ingestion_lag_seen\
| fillnull value=0 isOutlier\
| eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled)$"), isOutlier, 0)\
| fields - system_behaviour_analytic_mode\
| eval state = "icon|" + case(\
data_source_state=="green" AND data_monitoring_level="sourcetype" AND isOutlier=0, "ico_good ico_small|icon-check|Good: data source status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), and monitoring conditions are met.",\
data_source_state=="green" AND data_monitoring_level="index" AND isOutlier=0, "ico_good ico_small|icon-check|Good: data source status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), therefore data monitoring level is set at index level, which complies with a max lag of " . data_max_lag_allowed . " seconds for that index.",\
data_source_state=="red" AND isOutlier=0, "ico_error ico_small|icon-close|Alert: data source status is red, monitoring conditions are not met due to lagging or interruption in the data flow, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="red" AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data source status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="orange" AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data source status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_source_state=="orange" AND isnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, lagging conditions are met, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . " therefore week days rules conditions are not met.",\
data_source_state=="blue" AND isnotnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_unknown ico_small|icon-close|Info: data source does not honour lagging or week days monitoring conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_source_state=="orange" AND data_last_lag_seen<`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, detected data indexed in the future which is most likely due to timestamping misconfiguration, timezone or time synchronization issue, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . "."),\
monitoring = "icon|" + if(data_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: data source is being actively monitored", "ico_error ico_small|icon-close|Disabled: data source monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_host]
definition = fillnull value="NA" "data_last_time_seen (translated)", data_last_lag_seen, data_max_lag_allowed, data_last_ingestion_lag_seen\
| fillnull value=0 isOutlier\
| eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled)$"), isOutlier, 0)\
| fields - system_behaviour_analytic_mode\
| eval state = "icon|" + case(\
data_host_state=="green", "ico_good ico_small|icon-check|Good: data host status is green, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), and monitoring conditions are met.",\
data_host_state=="red" AND isnull(object_group_name) AND isOutlier=0, "ico_error ico_small|icon-close|Alert: data host status is red, monitoring conditions are not met due to lagging or interruption in the data flow, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="red" AND isnull(object_group_name) AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data host status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="orange" AND isnull(object_group_name) AND isOutlier=1, "ico_error ico_small|icon-close|Alert: data host status is red, monitoring conditions are not met due to outlier detection in the event count activity, review the Outlier detection window to investigate. For this source, latest data available is " . 'data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now) and ingestion latency is approximately " . data_last_ingestion_lag_seen . " seconds, max lag configured is " . data_max_lag_allowed . " seconds.",\
data_host_state=="red" AND isnotnull(object_group_name), "ico_error ico_small|icon-close|Alert: data host does not honour lagging or week days monitoring conditions, in addition it is a member of a logical group named: " . object_group_name . " which is not honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which does not comply with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_host_state=="orange" AND isnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data host status is orange, lagging conditions are met, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . " therefore week days rules conditions are not met.",\
data_host_state=="blue" AND isnotnull(object_group_name) AND data_last_lag_seen>=`trackme_future_indexing_tolerance`, "ico_unknown ico_small|icon-close|Info: data host does not honour lagging or week days monitoring conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
data_host_state=="orange" AND data_last_lag_seen<`trackme_future_indexing_tolerance`, "ico_warn ico_small|icon-close|Warn: data source status is orange, detected data indexed in the future which is most likely due to timestamping misconfiguration, timezone or time synchronization issue, latest data available is " . '	data_last_time_seen (translated)' . " (" . data_last_lag_seen . " seconds from now), max lag configured in seconds is " . data_max_lag_allowed . "."),\
monitoring = "icon|" + if(data_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: data host is being actively monitored", "ico_error ico_small|icon-close|Disabled: data host monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_metric_host]
definition = eval state = "icon|" + case(\
metric_host_state=="green", "ico_good ico_small|icon-check|Good: metric host status is green, latest data available is " . 'last time' . " (" . metric_last_lag_seen . " seconds from now)",\
metric_host_state=="red" AND isnull(object_group_name), "ico_error ico_small|icon-close|Alert: metric host status is red, lagging monitoring conditions are not met, latest data available is " . 'last time' . " (" . metric_last_lag_seen . " seconds from now)",\
metric_host_state=="red" AND isnotnull(object_group_name), "ico_error ico_small|icon-close|Alert: metric host does not honour lagging conditions, in addition it is a member of a logical group named: " . object_group_name . " which is not honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which does not comply with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)",\
metric_host_state=="blue" AND isnotnull(object_group_name), "ico_unknown ico_small|icon-close|Info: metric host does not honour lagging conditions therefore it is a member of a logical group named: " . object_group_name . " which is honouring monitoring rules , the group green status percentage is " . object_group_green_percent . " % which complies with a minimal " . object_group_min_green_percent . " % green members configured for that group." . "(members: " . 	object_group_members_count . "/ red status members count: " . 	object_group_members_red . ", latest data available for the group: " . object_group_last_lag_seen . " seconds from now)"),\
monitoring = "icon|" + if(metric_monitored_state=="enabled", "ico_good ico_small|icon-check|Enabled: metric host is being actively monitored", "ico_error ico_small|icon-close|Disabled: metric host monitoring is disabled")\
| rex field=state "[^\|]*\|[^\|]*\|[^\|]*\|(?<status_message>.*)"
iseval = 0

[trackme_eval_icons_metric_host_state_only]
definition = eval state = "icon|" + case(metric_host_state=="green", "ico_good ico_small|icon-check|Up: metric category is available and marked as green due to monitoring rules being met (metric last time seen: " . 	metric_last_time . ", " . metric_current_lag_sec . " seconds from now, which complies with a lagging configured of " . metric_max_lag_allowed . "seconds.)",\
metric_host_state=="red", "ico_error ico_small|icon-close|Down: metric category is not available and therefore marked as down due to rules monitoring (metric last time seen: " . 	metric_last_time . ", " . metric_current_lag_sec . " seconds from now, which does not comply with a lagging configured of " . metric_max_lag_allowed . " seconds.)")
iseval = 0

[trackme_eval_icons_flip]
definition = eval object_previous_state = "icon|" + case(\
object_previous_state=="green", "ico_good ico_small|icon-check|Up: object is available and marked as green due to monitoring rules being met",\
object_previous_state=="red", "ico_error ico_small|icon-close|Down: object is not available or marked as down due to rules monitoring",\
object_previous_state=="orange", "ico_warn ico_small|icon-close|Warn: object is not available but marked as warn due to monitoring rules",\
object_previous_state=="blue", "ico_unknown ico_small|icon-close|Info: object is not available therefore it is member of a logical group which monitoring rules are met",\
object_previous_state=="discovered", "ico_unknown ico_small|icon-close|Info: object was discovered and added to the collections"),\
object_state = "icon|" + case(object_state=="green", "ico_good ico_small|icon-check|Up: object is available and marked as green due to monitoring rules being met",\
object_state=="red", "ico_error ico_small|icon-close|Down: object is not available or marked as down due to rules monitoring",\
object_state=="orange", "ico_warn ico_small|icon-close|Warn: object is not available but marked as warn due to monitoring rules",\
object_state=="blue", "ico_unknown ico_small|icon-close|Info: object is not available therefore it is member of a logical group which monitoring rules are met")
iseval = 0

# Evaluate the data source status
[trackme_eval_data_source_state]
definition = eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval system_behaviour_analytic_mode=if(system_behaviour_analytic_mode="enabled" OR system_behaviour_analytic_mode="training" OR system_behaviour_analytic_mode="disabled", system_behaviour_analytic_mode, "enabled")\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| eval data_source_state=case(\
data_monitoring_level="index", if(data_last_lag_seen_idx>data_max_lag_allowed, "red", "green"),\
data_monitoring_level="sourcetype", if(data_last_lag_seen>data_max_lag_allowed OR data_last_ingestion_lag_seen>data_max_lag_allowed OR (isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="enabled"), "red", "green"))\
| eval data_source_state=if(isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="training", "orange", data_source_state)\
| fields - system_behaviour_analytic_mode\
| eval current_wday=strftime(now(), "%a")\
| eval current_wday_no=strftime(now(), "%w")\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):all_days") AND match(current_wday, ".*") AND data_source_state="red", "red", data_source_state)\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-friday") AND match(current_wday, "Sat|Sun") AND data_source_state="red", "orange", data_source_state)\
| eval data_source_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-saturday") AND match(current_wday, "Sun") AND data_source_state="red", "orange", data_source_state)\
| rex field=data_monitoring_wdays "^(manual|auto)\:(?<data_monitoring_wdays_no>\d.*)"\
| makemv delim="," data_monitoring_wdays_no\
| eval data_source_state=if(isnotnull(data_monitoring_wdays_no) AND current_wday_no!=data_monitoring_wdays_no AND data_source_state="red", "orange", data_source_state)\
| eval data_source_state=if(isnull(data_last_time_seen), "red", data_source_state)\
| eval data_source_state=if(data_last_lag_seen<`trackme_future_indexing_tolerance`, "orange", data_source_state)\
| fields - current_*, data_monitoring_wdays_no

# Evaluate the host status
[trackme_eval_data_host_state]
definition = eval system_behaviour_analytic_mode=`trackme_system_enable_behaviour_analytic_mode`\
| eval system_behaviour_analytic_mode=if(system_behaviour_analytic_mode="enabled" OR system_behaviour_analytic_mode="training" OR system_behaviour_analytic_mode="disabled", system_behaviour_analytic_mode, "enabled")\
| eval isOutlier=if(match(system_behaviour_analytic_mode, "(?i)^(enabled|training)$"), isOutlier, 0)\
| eval data_host_state=if(data_last_lag_seen>data_max_lag_allowed OR (isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="enabled"), "red", "green")\
| eval data_host_state=if(isOutlier=1 AND enable_behaviour_analytic="true" AND system_behaviour_analytic_mode="training", "orange", data_host_state)\
| fields - system_behaviour_analytic_mode\
| eval current_wday=strftime(now(), "%a")\
| eval current_wday_no=strftime(now(), "%w")\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):all_days") AND match(current_wday, ".*") AND data_host_state="red", "red", data_host_state)\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-friday") AND match(current_wday, "Sat|Sun") AND data_host_state="red", "orange", data_host_state)\
| eval data_host_state=if(match(data_monitoring_wdays, "^(auto|manual):monday-to-saturday") AND match(current_wday, "Sun") AND data_host_state="red", "orange", data_host_state)\
| rex field=data_monitoring_wdays "^(manual|auto)\:(?<data_monitoring_wdays_no>\d.*)"\
| makemv delim="," data_monitoring_wdays_no\
| eval data_host_state=if(isnotnull(data_monitoring_wdays_no) AND current_wday_no!=data_monitoring_wdays_no AND data_host_state="red", "orange", data_host_state)\
| eval data_host_state=if(isnull(data_last_time_seen), "red", data_host_state)\
| eval data_host_state=if(data_last_lag_seen<`trackme_future_indexing_tolerance`, "orange", data_host_state)\
| fields - current_*, data_monitoring_wdays_no

# data source macro abstract
[trackme_data_source_tracker_abstract]
definition = `comment("#### define the ingestion lag versus now, and a flag field defining an online status any results from live tstats ####")`\
| eval data_last_lag_seen=now()-data_last_time_seen, data_source_is_online="true"\
\
`comment("#### lookup the collection to retrieve the KVstore key and other fields to be preserved for this source ####")`\
| lookup local=t trackme_data_source_monitoring data_name OUTPUT _key as key, data_first_time_seen as data_first_time_seen,\
data_source_state as data_previous_source_state, data_tracker_runtime as data_previous_tracker_runtime,\
data_override_lagging_class, data_max_lag_allowed, data_monitoring_level,\
data_monitoring_wdays, data_monitored_state, priority,\
OutlierMinEventCount, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, isOutlier\
\
`comment("#### if the key is null, this is the first time we see this source and it will be added to the collection, create a key ####")`\
| eval key=if(isnull(key), md5(data_name), key)\
\
`comment("#### handle source first time seen ####")`\
| eval data_first_time_seen=if(isnum(data_first_time_seen), data_first_time_seen, current_data_first_time_seen)\
| fields - current_data_first_time_seen\
\
`comment("#### apply default policies ####")`\
| `trackme_default_monitored_state`\
| `trackme_default_lag`\
| `trackme_default_monitored_wdays`\
| `trackme_default_priority`\
\
`comment("#### handle override lagging class ####")`\
| eval data_override_lagging_class=if(isnull(data_override_lagging_class) OR data_override_lagging_class="null", "false", data_override_lagging_class)\
\
`comment("#### lookup any defined rule for max lagging based on index or sourcetype ####")`\
| lookup trackme_custom_lagging_definition name as data_index OUTPUTNEW value as data_custom_max_lag_allowed\
| lookup trackme_custom_lagging_definition name as data_sourcetype OUTPUTNEW value as data_custom_max_lag_allowed\
\
`comment("#### conditionally handle data_max_lag_allowed ####")`\
| eval data_max_lag_allowed	=if(isnum(data_custom_max_lag_allowed) AND data_override_lagging_class!="true", data_custom_max_lag_allowed, data_max_lag_allowed)\
| fields - data_custom_max_lag_allowed\
\
`comment("#### exclude any permanent deletion stored in the trackme_audit_change lookup ####")`\
| search NOT [ | inputlookup trackme_audit_changes | where action="success" AND change_type="delete permanent" | eval _time=time/1000 | where _time>relative_time(now(), "-7d") | table object | dedup object | sort limit=0 object | rename object as data_name ]\
\
`comment("#### conditionally define data_monitoring_level ####")`\
| eval data_monitoring_level=if(isnull(data_monitoring_level), "sourcetype", data_monitoring_level)\
\
`comment("#### calculate last time seen and lag per index ####")`\
| eventstats max(data_last_time_seen) as data_last_time_seen_idx, min(data_last_lag_seen) as data_last_lag_seen_idx by data_index\
\
`comment("#### filter sources ####")`\
| `trackme_data_sources_filtering`\
\
`comment("#### define the object_category field which is used by further lookup operations ####")`\
| eval object_category="data_source"\
\
`comment("#### retrieve summary investigator analytic ####")`\
| lookup trackme_summary_investigator object_category, object as data_name OUTPUT isOutlier\
\
`comment("#### fillnull for OutlierMinEventCount, isOutlier ####")`\
| fillnull value="NA" OutlierMinEventCount\
| fillnull value=0 isOutlier\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Define the behaviour for alerting on upper bound ####")`\
| eval OutlierAlertOnUpper=if(isnotnull(OutlierAlertOnUpper), OutlierAlertOnUpper, `trackme_default_outlier_alert_on_upper`)\
\
`comment("#### Define the default period for Outliers calculations ####")`\
| eval OutlierTimePeriod=if(isnotnull(OutlierTimePeriod), OutlierTimePeriod, `trackme_default_outlier_period`)\
\
`comment("#### define a status for enable_behaviour_analytic ####")`\
| eval enable_behaviour_analytic=if(isnull(enable_behaviour_analytic) OR enable_behaviour_analytic="", `trackme_default_enable_behaviour_analytic`, enable_behaviour_analytic)\
\
`comment("#### eval state source ####")`\
| `trackme_eval_data_source_state`\
\
`comment("#### data_tracker_runtime is now ####")`\
| eval data_tracker_runtime=now()\
\
`comment("#### lookup latest flipping states from audit ####")`\
| lookup trackme_audit_flip_latest object_category, object as data_name OUTPUT latest_flip_time as current_latest_flip_time, latest_flip_state as current_latest_flip_state\
\
`comment("#### define flip time and state ####")`\
| eval latest_flip_time=if(isnotnull(current_latest_flip_time), current_latest_flip_time, latest_flip_time)\
| eval latest_flip_state=if(isnotnull(current_latest_flip_state), current_latest_flip_state, latest_flip_state)\
| fields - current_latest_flip_time, current_latest_flip_state\
\
`comment("#### conditional verifications ####")`\
| eval data_previous_source_state=if(isnull(data_previous_source_state), "discovered", data_previous_source_state)\
| where isnotnull(data_last_time_seen)\
| eval data_last_lag_seen=if(data_source_is_online="true", data_last_lag_seen, now()-data_last_time_seen)\
\
`comment("#### auto disable monitoring status based on policies ####")`\
| eval data_monitored_state=if(data_last_time_seen<=`trackme_auto_disablement_period`, "disabled", data_monitored_state)
iseval = 0

# Automatic monitored_state disablement based on latest event received
[trackme_auto_disablement_period]
definition = relative_time(now(), "-45d")
iseval = 0

# Evaluate the per metric entity status (metric_category)
[trackme_eval_metric_category_state]
definition = eval detail_metric_host_state=if(detail_metric_current_lag_sec>detail_metric_max_lag_allowed, "red", "green")

# Evaluate the metric host status
[trackme_eval_metric_host_state]
definition = eval metric_host_state=if(match(metric_details, "metric_host_state=red"), "red", "green")

# For blacklists, detect if blacklist entry is a regular expression
[detect_rex(1)]
definition = eval is_rex=if(match($key$, "[\\\|\?|\$|\^|\[|\]|\{|\}|\+]"), "true", "false")\
| eval is_rex=if(match($key$, "\.\*"), "true", is_rex)
args = key
iseval = 0

# Blacklist exclusion for regular expression support
[apply_blacklist_rex(2)]
definition = | inputlookup $collection$ | `detect_rex($key$)` | where is_rex="true" | table $key$ | format\
| fields search\
| rex field=search mode=sed "s/$key$=/match($key$, /g"\
| rex field=search mode=sed "s/\( match/match/g"\
| rex field=search mode=sed "s/NOT \(\)/match($key$, \"null\")/g" | return $search
args = collection, key
iseval = 0

[apply_blacklist_rex(3)]
definition = | inputlookup $collection$ | `detect_rex($key$)` | where is_rex="true" | table $key$ | rename $key$ as $newkey$ | format\
| fields search\
| rex field=search mode=sed "s/$newkey$=/match($newkey$, /g"\
| rex field=search mode=sed "s/\( match/match/g"\
| rex field=search mode=sed "s/NOT \(\)/match($newkey$, \"null\")/g" | return $search
args = collection, key, newkey
iseval = 0

# Blacklist exclusions
[apply_data_source_blacklists_data_retrieve]
definition = NOT [ | inputlookup trackme_data_source_monitoring_blacklist_host | `detect_rex(data_host)` | where is_rex="false" | rename data_host as host | table host ] NOT [ | inputlookup trackme_data_source_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | rename data_index as index | table index ] NOT [ | inputlookup trackme_data_source_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | rename data_sourcetype as sourcetype | table sourcetype ]
iseval = 0

[apply_data_host_blacklists_data_retrieve]
definition = NOT [ | inputlookup trackme_data_host_monitoring_blacklist_host | `detect_rex(data_host)` | where is_rex="false" | rename data_host as host | table host ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | rename data_index as index | table index ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | rename data_sourcetype as sourcetype | table sourcetype ]
iseval = 0

[apply_metric_host_blacklists_data_retrieve]
definition = NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_host | `detect_rex(metric_host)` | where is_rex="false" | rename metric_host as host | table host ] NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_index | `detect_rex(metric_index)` | where is_rex="false" | rename metric_index as index | table index ]
iseval = 0

[apply_data_source_blacklists]
definition = search NOT [ | inputlookup trackme_data_source_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | table data_index ] NOT [ | inputlookup trackme_data_source_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | table data_sourcetype ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_index, data_index)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_sourcetype, data_sourcetype)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_source_monitoring_blacklist_host, data_host)` ]
iseval = 0

[apply_data_host_blacklists]
definition = search NOT [ | inputlookup trackme_data_host_monitoring_blacklist_host | `detect_rex(data_host)` | where is_rex="false" | table data_host ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_index | `detect_rex(data_index)` | where is_rex="false" | table data_index ] NOT [ | inputlookup trackme_data_host_monitoring_blacklist_sourcetype | `detect_rex(data_sourcetype)` | where is_rex="false" | table data_sourcetype ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_index, data_index)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_sourcetype, data_sourcetype)` ]\
| where NOT [ `apply_blacklist_rex(trackme_data_host_monitoring_blacklist_host, data_host)` ]
iseval = 0

[apply_metric_host_blacklists]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_host | `detect_rex(metric_host)` | where is_rex="false" | table metric_host ] NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_index | `detect_rex(metric_index)` | where is_rex="false" | table metric_index ]\
| where NOT [ `apply_blacklist_rex(trackme_metric_host_monitoring_blacklist_host, metric_host)` ]\
| where NOT [ `apply_blacklist_rex(trackme_metric_host_monitoring_blacklist_index, metric_index)` ]
iseval = 0

[apply_metric_host_blacklists_metric_category]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category ]
iseval = 0

[apply_metric_host_blacklists_detail_metric_category]
definition = search NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category ] NOT [ | inputlookup trackme_metric_host_monitoring_blacklist_metric_category | table metric_category | rename metric_category as detail_metric_category ]
iseval = 0

# Default retention for audit changes, in relative time format.
# Default is 90d
[trackme_audit_changes_retention]
definition =  where _time>relative_time(now(), "-90d")
iseval = 0

# Default retention for flip states, in relative time format.
# Default is 90d
[trackme_flip_state_retention]
definition =  where _time>relative_time(now(), "-90d")
iseval = 0

# Default priority levels for OOTB alerts
[trackme_alerts_priority]
definition = priority="medium" OR priority="high"
iseval = 0

# whitelist indexes
[trackme_get_idx_whitelist(2)]
args = lookup, outname
definition = [ | inputlookup $lookup$\
| getidxwhitelist fieldname=word_count pattern="\\w+" outname=$outname$ $outname$\
| rex max_match=0 "\(\'$outname$\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index ]
iseval = 0

[trackme_get_idx_whitelist_searchtime(2)]
args = lookup, outname
definition = [ | inputlookup $lookup$\
| getidxwhitelist fieldname=word_count pattern="\\w+" outname=$outname$ $outname$\
| rex max_match=0 "\(\'$outname$\'\, \'(?<index>[^\']*)\'\)" | fields - _raw | mvexpand index | rename index as $outname$ ]
iseval = 0

# TrackMe data source identity card
[trackme_get_identity_card(1)]
args = key
definition = lookup trackme_sources_knowledge object as $key$\
| eval doc_link=if(isnull(doc_link), "null", doc_link), doc_note=if(isnull(doc_note), "null", doc_note)
iseval = 0

# Ack default duration in seconds
[trackme_ack_default_duration]
definition = 86400
iseval = 0

# Ack add
[trackme_ack_add(3)]
definition = makeresults\
| eval object="$object$", object_category="$object_category$"\
| rename _time as ack_mtime\
| eval ack_expiration=now()+($ack_duration$), ack_state="active"\
| fields object, object_category, ack_mtime, ack_expiration, ack_state\
| append [ | inputlookup trackme_alerts_ack | where NOT (object="$object$" AND object_category="$object_category$") ]\
| outputlookup trackme_alerts_ack
args = object, object_category, ack_duration
iseval = 0

# Ack get
[trackme_ack_get(2)]
definition = makeresults\
| eval object="$object$", object_category="$object_category$"\
| lookup trackme_alerts_ack object object_category OUTPUT | rename _key as keyid\
| table keyid, object, object_category, ack_mtime, ack_expiration, ack_state | fields - _time\
| eval ack_state=if(isnull(ack_state), "inactive", ack_state)\
| eval ack_mtime=if(ack_state="active", strftime(ack_mtime, "%c"), "N/A"), ack_expiration=if(ack_state="active", strftime(ack_expiration, "%c"), "N/A")
args = object, object_category
iseval = 0

# Ack lookup
[trackme_ack_lookup(2)]
definition = eval object_category="$object_category$" | lookup trackme_alerts_ack object as $object$ object_category | eval ack_state=if(isnull(ack_state), "inactive", ack_state) | where ack_state!="active" | fields - ack_*
args = object, object_category
iseval = 0

# Ack disable
[trackme_ack_disable(1)]
definition = inputlookup trackme_alerts_ack | eval keyid=_key\
| eval ack_state=if(keyid="$keyid$", "inactive", ack_state)\
| eval ack_expiration=if(ack_state="inactive", "N/A", ack_expiration), ack_mtime=if(ack_state="inactive", "N/A", ack_mtime) | fields keyid, *\
| outputlookup append=t trackme_alerts_ack key_field=keyid
args = keyid
iseval = 0

# Logical group for data host monitoring
[trackme_data_host_group_lookup]
definition = eval object_category="data_host" | lookup trackme_logical_group object_group_members as data_host OUTPUTNEW _key as object_group_key, object_group_name, object_group_min_green_percent\
| eventstats count as object_group_members_count, min(data_last_lag_seen) as object_group_last_lag_seen, count(eval(data_host_state="red")) as object_group_members_red by object_group_key, object_group_name\
| eval object_group_green_percent=100-(object_group_members_red/object_group_members_count*100)\
| eval data_host_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND data_host_state!="green" AND object_group_green_percent>=object_group_min_green_percent, "blue", data_host_state)\
| eval object_group_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND object_group_green_percent>=object_group_min_green_percent, "green", "red")
iseval = 0

# Logical group for metric host monitoring
[trackme_metric_host_group_lookup]
definition = eval object_category="metric_host" | lookup trackme_logical_group object_group_members as metric_host OUTPUTNEW _key as object_group_key, object_group_name, object_group_min_green_percent\
| eventstats count as object_group_members_count, min(metric_last_lag_seen) as object_group_last_lag_seen, count(eval(metric_host_state="red")) as object_group_members_red by object_group_key, object_group_name\
| eval object_group_green_percent=100-(object_group_members_red/object_group_members_count*100)\
| eval metric_host_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND metric_host_state!="green" AND object_group_green_percent>=object_group_min_green_percent, "blue", metric_host_state)\
| eval object_group_state=if(isnotnull(object_group_key) AND isnotnull(object_group_name) AND object_group_green_percent>=object_group_min_green_percent, "green", "red")
iseval = 0

# Load audit flip collection for SLA compliance
[trackme_get_sla_root]
definition = inputlookup trackme_audit_flip | sort limit=0 - time | eval _time=time\
| addinfo | where _time>=info_min_time AND (_time<=info_max_time OR info_max_time="+Infinity")\
`comment("#### Once the collection is loaded and the time field defined, lookup main collection for enrichment purposes")`\
| lookup trackme_data_source_monitoring data_name as object OUTPUTNEW data_monitored_state as monitored_state, data_last_time_seen as last_time_seen, priority\
| lookup trackme_host_monitoring data_host as object OUTPUTNEW data_monitored_state as monitored_state, data_last_time_seen as last_time_seen, priority\
| lookup trackme_metric_host_monitoring metric_host as object OUTPUTNEW metric_monitored_state as monitored_state, metric_last_time_seen as last_time_seen, priority\
`comment("#### Retrieve data_source objects for which no flipping states where recorded ####")`\
| append [\
| inputlookup trackme_data_source_monitoring | where data_monitored_state="enabled" | addinfo\
| lookup trackme_audit_flip object as data_name OUTPUT object as FOUND | where isnull(FOUND) | fields - FOUND\
| eval object=data_name, time=if(info_min_time>data_first_time_seen, info_min_time, data_first_time_seen), object_state=data_source_state, last_time_seen=data_last_time_seen, object_category="data_source", monitored_state=data_monitored_state, object_previous_state="N/A", result="No flipping state records", _time=time\
| where isnum(_time)\
| fields _time, last_time_seen, monitored_state	object, object_category, object_previous_state, object_state, priority, result, time\
]\
`comment("#### Retrieve data_host objects for which no flipping states where recorded ####")`\
| append [\
| inputlookup trackme_host_monitoring | where data_monitored_state="enabled" | addinfo\
| lookup trackme_audit_flip object as data_host OUTPUT object as FOUND | where isnull(FOUND) | fields - FOUND\
| eval object=data_host, time=if(info_min_time>data_first_time_seen, info_min_time, data_first_time_seen), object_state=data_host_state, last_time_seen=data_last_time_seen, object_category="data_host", monitored_state=data_monitored_state, object_previous_state="N/A", result="No flipping state records", _time=time\
| where isnum(_time)\
| fields _time, last_time_seen, monitored_state	object, object_category, object_previous_state, object_state, priority, result, time\
]\
`comment("#### Retrieve data_host objects for which no flipping states where recorded ####")`\
| append [\
| inputlookup trackme_metric_host_monitoring | where metric_monitored_state="enabled" | addinfo\
| lookup trackme_audit_flip object as metric_host OUTPUT object as FOUND | where isnull(FOUND) | fields - FOUND\
| eval object=metric_host, time=if(info_min_time>metric_first_time_seen, info_min_time, metric_first_time_seen), object_state=metric_host_state, last_time_seen=metric_last_time_seen, object_category="metric_host", monitored_state=metric_monitored_state, object_previous_state="N/A", result="No flipping state records", _time=time\
| where isnum(_time)\
| fields _time, last_time_seen, monitored_state	object, object_category, object_previous_state, object_state, priority, result, time\
]
iseval = 0

# Get SLA compliance table
[trackme_get_sla(4)]
definition = `trackme_get_sla_root`\
`comment("#### Apply filters as soon as possible ####")`\
| search object_category=$object_category$ object=$object_filter1$ object=$object_filter2$\
`comment("#### To remove any pollution during the SLA compliance calculation, filter on active objects ####")`\
| where isnotnull(monitored_state) AND monitored_state="enabled" AND last_time_seen>=relative_time(now(), "-15d@d")\
`comment("#### Apply filters as soon as possible ####")`\
| search priority=$priority$\
`comment("#### sort by time ####")`\
| sort limit=0 _time\
`comment("#### use streamstats to get the previous time value to determine the time spent in each mode ####")`\
| streamstats last(_time) as previous_time current=f by object, object_category\
`comment("#### get entries numbers and total entries number for further processing ####")`\
| streamstats count as number_entry by object, object_category\
| eventstats count as number_total by object, object_category\
`comment("#### The following is used to get the next value of time for the very first entry from the collection on a per base statement ####")`\
| eval combo = number_entry . ":" . time\
| eventstats list(combo) as combo by object, object_category\
| rex max_match=1 field=combo "^2:(?<time_second_entry>\d*)$"\
| fields - combo\
`comment("#### Perform the duration calculation and results formatting, there are different steps, states and conditions to cover all cases, purpose is getting the time spent in seconds for each state ####")`\
| eval duration_green=case(\
(match(result, "has flipped from previous_state=(green|blue|discovered) to state=(red|orange)") AND (number_entry != number_total) AND isnum(previous_time) ), (time - previous_time)\
)\
| eval duration_not_green=case(\
(match(result, "has flipped from previous_state=(red|orange) to state=(green|blue|discovered)") AND (number_entry != number_total) AND isnum(previous_time) ), (time - previous_time)\
)\
| eval duration_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(red|orange) to state=(green|blue|discovered)"), now() - time, duration_green)\
| eval duration_not_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(green|blue|discovered) to state=(red|orange)"), now() - time, duration_not_green)\
| eval duration_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(green|blue|discovered) to state=(red|orange)"), time-previous_time, duration_green)\
| eval duration_not_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(red|orange) to state=(green|blue|discovered)"), time-previous_time, duration_not_green)\
| stats sum(duration_green) as total_duration_green, sum(duration_not_green) as duration_not_green, latest(object_state) as last_object_state, first(monitored_state) as monitored_state, first(priority) as priority by object, object_category\
| fillnull total_duration_green, duration_not_green\
| eval total_duration=(total_duration_green + duration_not_green)\
| eval percent_sla=round(total_duration_green/total_duration*100, 2)\
| eval percent_sla=if(isnull(percent_sla) AND last_object_state="green", "100.00", percent_sla)\
| eval percent_sla=if(isnull(percent_sla), "0.00", percent_sla)\
| fields object, object_category, priority, monitored_state, percent_sla
args = object_category, object_filter1, object_filter2, priority
iseval = 0

# Get SLA compliance results for a particular object
[trackme_get_sla(2)]
definition = `trackme_get_sla_root`\
`comment("#### Apply filters as soon as possible ####")`\
| search object=$object$ object_category=$object_category$\
`comment("#### sort by time ####")`\
| sort limit=0 _time\
`comment("#### use streamstats to get the previous time value to determine the time spent in each mode ####")`\
| streamstats last(_time) as previous_time current=f by object, object_category\
`comment("#### get entries numbers and total entries number for further processing ####")`\
| streamstats count as number_entry by object, object_category\
| eventstats count as number_total by object, object_category\
`comment("#### The following is used to get the next value of time for the very first entry from the collection on a per base statement ####")`\
| eval combo = number_entry . ":" . time\
| eventstats list(combo) as combo by object, object_category\
| rex max_match=1 field=combo "^2:(?<time_second_entry>\d*)$"\
| fields - combo\
`comment("#### Perform the duration calculation and results formatting, there are different steps, states and conditions to cover all cases, purpose is getting the time spent in seconds for each state ####")`\
| eval duration_green=case(\
(match(result, "has flipped from previous_state=(green|blue) to state=(red|orange)") AND (number_entry != number_total) AND isnum(previous_time) ), (time - previous_time)\
)\
| eval duration_not_green=case(\
(match(result, "has flipped from previous_state=(red|orange) to state=(green|blue)") AND (number_entry != number_total) AND isnum(previous_time) ), (time - previous_time)\
)\
| eval duration_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(red|orange) to state=(green|blue|discovered)"), now() - time, duration_green)\
| eval duration_not_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(green|blue|discovered) to state=(red|orange)"), now() - time, duration_not_green)\
| eval duration_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(green|blue|discovered) to state=(red|orange)"), time-previous_time, duration_green)\
| eval duration_not_green = if( number_entry = number_total AND match(result, "has flipped from previous_state=(red|orange) to state=(green|blue|discovered)"), time-previous_time, duration_not_green)\
`comment("#### Convert duration seconds to human readable format ####")`\
| eval duration_green=tostring(duration_green, "duration"), duration_not_green=tostring(duration_not_green, "duration")\
| fields - time_second_entry, previous_time, time\
| fields _time, object_category, object, object_state, object_previous_state, result, duration_green, duration_not_green, number_entry, number_total, *
args = object, object_category
iseval = 0

#
# Enrichment tags
#

[trackme_tags_default_message]
definition = eval tags =  "Tags enrichment is not configured yet, consult the configuration UI TrackMe manage and configure."
iseval = 0

# data_host_tags
[trackme_get_data_host_tags]
definition = `trackme_tags_default_message`
iseval = 0

# metric_host_tags
[trackme_get_metric_host_tags]
definition = `trackme_tags_default_message`
iseval = 0

#
# Behaviour analytic
#

# This enable / disable behaviour analytic widely, default to enabled, defined to disabled to completely switch off the features
# related to behaviour analytic
[trackme_system_enable_behaviour_analytic_mode]
definition = "enabled"
iseval = 0

# This defines the default status for behaviour analytic, true / false, where default to true
# The default status defined by this macro is handled when the entity is first added to the collection
[trackme_default_enable_behaviour_analytic]
definition = "true"
iseval = 0

# This defines the default value for the outlier detection threshold multiplier, default to 2
[trackme_default_outlier_threshold_multiplier]
definition = 4
iseval = 0

# This defines the default mode for upper bound outliers detection, by default it is disabled
[trackme_default_outlier_alert_on_upper]
definition = "false"
iseval = 0

# This defines the default period for outliers calculations
[trackme_default_outlier_period]
definition = "-7d"
iseval = 0

# Summary Investigator abstract
[trackme_summary_investigator_abstract]
definition = `comment("#### define the object_category and object fields based on the source value ####")`\
| eval object_category=case(source="trackme_datasource_tracker_shorterm", "data_source", source="trackme_datahost_tracker_shorterm", "data_host")\
| eval object=case(source="trackme_datasource_tracker_shorterm", data_name, source="trackme_datahost_tracker_shorterm", data_host)\
\
`comment("#### Do not use any of the stored values for OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic ####")`\
| fields - OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Lookup outlier configuration ####")`\
| lookup trackme_data_source_monitoring data_name as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
| lookup trackme_host_monitoring data_host as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Restrict calculations to the OutlierTimePeriod ####")`\
| eval data_eventcount=if(_time>=relative_time(now(), OutlierTimePeriod), data_eventcount, "")\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| eventstats avg("data_eventcount") as avg stdev("data_eventcount") as stdev by object_category, object\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact(OutlierLowerThresholdMultiplier)), upperBound=(avg+stdev*exact(OutlierUpperThresholdMultiplier))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(isnum(OutlierMinEventCount) AND OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### In the context of event count behaviour analytic, we care about outliers that are bellow the lower bound detection ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, "")\
| eval isOutlier=if('data_eventcount' < lowerBound OR 'data_eventcount' < OutlierMinEventCount, 1, 0)\
`comment("#### Define status regarding upperBound ####")`\
| eval isOutlier=if('data_eventcount' > upperBound AND match(OutlierAlertOnUpper, "^true$"), 1, isOutlier)\
\
`comment("#### Register the latest values ####")`\
| stats max(data_tracker_runtime) as data_tracker_runtime, latest(isOutlier) as isOutlier,\
first(OutlierTimePeriod) as OutlierTimePeriod,\
first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier,\
first(OutlierAlertOnUpper) as OutlierAlertOnUpper,\
first(enable_behaviour_analytic) as enable_behaviour_analytic\
latest(lowerBound) as lowerBound, latest(upperBound) as upperBound, latest(stdev) as stdev by object_category, object\
\
`comment("#### Store current time ####")`\
| eval update_time=now()
iseval = 0


# outlier chart
[trackme_outlier_chart(4)]
definition = `trackme_idx` source="$source$" $key$="$object$"\
`comment("#### Summary data is loaded ####")`\
\
`comment("#### define the object_category and object fields based on the source value ####")`\
| eval object_category=case(source="trackme_datasource_tracker_shorterm", "data_source", source="trackme_datahost_tracker_shorterm", "data_host")\
| eval object=case(source="trackme_datasource_tracker_shorterm", data_name, source="trackme_datahost_tracker_shorterm", data_host)\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| eventstats avg("data_eventcount") as avg stdev("data_eventcount") as stdev by "$key$"\
\
`comment("#### Do not use any of the stored values for OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic ####")`\
| fields - OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Lookup outlier configuration ####")`\
| lookup trackme_data_source_monitoring data_name as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
| lookup trackme_host_monitoring data_host as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Define the behaviour for alerting on upper bound ####")`\
| eval OutlierAlertOnUpper=if(isnotnull(OutlierAlertOnUpper), OutlierAlertOnUpper, `trackme_default_outlier_alert_on_upper`)\
\
`comment("#### Define the default period for Outliers calculations ####")`\
| eval OutlierTimePeriod=if(isnotnull(OutlierTimePeriod), OutlierTimePeriod, `trackme_default_outlier_period`)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact(OutlierLowerThresholdMultiplier)), upperBound=(avg+stdev*exact(OutlierUpperThresholdMultiplier))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(isnum(OutlierMinEventCount) AND OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### Define status regarding lowerBound ####")`\
| eval isOutlier=if('data_eventcount' < lowerBound, 1, 0)\
`comment("#### Define status regarding upperBound ####")`\
| eval isOutlier=if('data_eventcount' > upperBound AND match(OutlierAlertOnUpper, "^true$"), 1, isOutlier)\
\
`comment("#### Finally, provides the results ####")`\
| eval _split_by="$key$"\
| rename data_eventcount as eventcount_4h_span\
| table _time, "eventcount_4h_span", lowerBound, upperBound
args = source, object_category, object, key
iseval = 0

# outlier table
[trackme_outlier_table(4)]
definition = `trackme_idx` source="$source$" $key$="$object$"\
`comment("#### Summary data is loaded ####")`\
\
`comment("#### define the object_category and object fields based on the source value ####")`\
| eval object_category=case(source="trackme_datasource_tracker_shorterm", "data_source", source="trackme_datahost_tracker_shorterm", "data_host")\
| eval object=case(source="trackme_datasource_tracker_shorterm", data_name, source="trackme_datahost_tracker_shorterm", data_host)\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| eventstats avg("data_eventcount") as avg stdev("data_eventcount") as stdev by "$key$"\
\
`comment("#### Do not use any of the stored values for OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic ####")`\
| fields - OutlierTimePeriod, OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Lookup outlier configuration ####")`\
| lookup trackme_data_source_monitoring data_name as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
| lookup trackme_host_monitoring data_host as object, object_category OUTPUTNEW OutlierTimePeriod, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, OutlierMinEventCount, enable_behaviour_analytic\
\
`comment("#### Define the default outlier threshold multiplier ####")`\
| eval OutlierLowerThresholdMultiplier=if(isnum(OutlierLowerThresholdMultiplier), OutlierLowerThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
| eval OutlierUpperThresholdMultiplier=if(isnum(OutlierUpperThresholdMultiplier), OutlierUpperThresholdMultiplier, `trackme_default_outlier_threshold_multiplier`)\
\
`comment("#### Define the behaviour for alerting on upper bound ####")`\
| eval OutlierAlertOnUpper=if(isnotnull(OutlierAlertOnUpper), OutlierAlertOnUpper, `trackme_default_outlier_alert_on_upper`)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact(OutlierLowerThresholdMultiplier)), upperBound=(avg+stdev*exact(OutlierUpperThresholdMultiplier))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(isnum(OutlierMinEventCount) AND OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### In the context of event count behaviour analytic, we care about outliers that are bellow the lower bound detection ####")`\
| eval OutlierMinEventCount=if(isnum(OutlierMinEventCount), OutlierMinEventCount, "")\
\
`comment("#### Define status regarding lowerBound ####")`\
| eval isOutlier=if('data_eventcount' < lowerBound OR 'data_eventcount' < OutlierMinEventCount, 1, 0)\
`comment("#### Define status regarding upperBound ####")`\
| eval isOutlier=if('data_eventcount' > upperBound AND match(OutlierAlertOnUpper, "^true$"), 1, isOutlier)\
\
`comment("#### Register the latest values ####")`\
| stats max(data_tracker_runtime) as data_tracker_runtime, latest(isOutlier) as isOutlier,\
first(OutlierTimePeriod) as OutlierTimePeriod,\
first(OutlierMinEventCount) as OutlierMinEventCount,\
first(OutlierLowerThresholdMultiplier) as OutlierLowerThresholdMultiplier, first(OutlierUpperThresholdMultiplier) as OutlierUpperThresholdMultiplier,\
first(OutlierAlertOnUpper) as OutlierAlertOnUpper,\
first(enable_behaviour_analytic) as enable_behaviour_analytic,\
latest(lowerBound) as lowerBound, latest(upperBound) as upperBound, latest(stdev) as stdev by object_category, object\
\
`comment("#### store and update the collection entities ####")`\
| eval key = md5(object_category . ":" . object)\
\
`comment("#### format ####")`\
| fields enable_behaviour_analytic, OutlierTimePeriod, isOutlier, OutlierMinEventCount, OutlierLowerThresholdMultiplier, OutlierUpperThresholdMultiplier, OutlierAlertOnUpper, lowerBound, upperBound, stdev\
| foreach lowerBound, upperBound, stdev [ eval <<FIELD>> = round('<<FIELD>>', 2) ]\
| rename enable_behaviour_analytic as "enable outlier", OutlierLowerThresholdMultiplier as "lower multiplier", OutlierUpperThresholdMultiplier as "upper multiplier", OutlierAlertOnUpper as "alert on upper"
args = source, object_category, object, key

# outlier chart
[trackme_outlier_chart_simulate(7)]
definition = `trackme_idx` source="$source$" $key$="$object$"\
`comment("#### Summary data is loaded ####")`\
\
`comment("#### define the object_category and object fields based on the source value ####")`\
| eval object_category=case(source="trackme_datasource_tracker_shorterm", "data_source", source="trackme_datahost_tracker_shorterm", "data_host")\
| eval object=case(source="trackme_datasource_tracker_shorterm", data_name, source="trackme_datahost_tracker_shorterm", data_host)\
\
`comment("#### Perform standard deviation calculation of event counts registered ####")`\
| eventstats avg("data_eventcount") as avg stdev("data_eventcount") as stdev by "$key$"\
\
`comment("#### Define OutlierMinEventCount ####")`\
| eval OutlierMinEventCount=if(isnum($mineventcount$), $mineventcount$, -1)\
\
`comment("#### Lower bound and Upper bound calculation ####")`\
| eval lowerBound=(avg-stdev*exact($minmultiplier$)), upperBound=(avg+stdev*exact($uppermultiplier$))\
\
`comment("#### Lower bound cannot be negative ####")`\
| eval lowerBound=if(lowerBound<0, 0, lowerBound)\
\
`comment("#### if OutlierMinEventCount is used, then lowerbound becomes a static value ####")`\
| eval lowerBound=if(OutlierMinEventCount>0, OutlierMinEventCount, lowerBound)\
\
`comment("#### In the context of event count behaviour analytic, we care about outliers that are bellow the lower bound detection ####")`\
| eval isOutlier=if('data_eventcount' < lowerBound, 1, 0)\
| eval isOutlier=if('data_eventcount' > upperBound, 1, isOutlier)\
\
`comment("#### Finally, provides the results ####")`\
| eval _split_by="$key$"\
| rename data_eventcount as eventcount_4h_span\
| table _time, "eventcount_4h_span", lowerBound, upperBound
args = source, object_category, object, key, minmultiplier, uppermultiplier, mineventcount
iseval = 0

#
# outputlookup macros from trackers
#

[trackme_outputlookup(2)]
definition = outputlookup $collection$ append=t key_field=$key$
args = collection, key
iseval = 0

#
# collect macros from trackers
#

[trackme_sumarycollect(1)]
definition = eval _time=now() | collect `trackme_idx` source=$report$
args = report
iseval = 0

#
# Various
#

[trackme_donut_alert_by_type(1)]
definition = eval color=case(\
$key$="green", "#77dd77",\
$key$="blue", "#779ecb",\
$key$="orange", "#ffb347",\
$key$="red - other priority", "#ffb347",\
$key$="red - high priority", "#ff6961")\
| eval order=case(\
$key$="green", 0,\
$key$="blue", 1,\
$key$="orange", 2,\
$key$="red - other priority", 3,\
$key$="red - other priority", 4)\
| sort order | fields - order
args = key
iseval = 0

[trackme_donut_alert_by_priority]
definition = eval color=case(\
priority="low", "#cce5ff",\
priority="medium", "#7fbfff",\
priority="high", "#3298ff")\
| eval order=case(\
priority="low", 0,\
priority="medium", 1,\
priority="high", 2)\
| sort order | fields - order
iseval = 0

# used to generate SPL for simulation
[trackme_eval_spl]
definition = eval spl=case(\
search_mode="tstats", "| " . search_mode . " max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " where " . search_constraint . " | eval data_name=\"" . data_name . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="raw", search_constraint . " | stats max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " | eval data_name=\"" . data_name . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="from", "| " . search_mode . " " . from_part1 . " | " . from_part2 . " | stats max(_indextime) as data_last_ingest, min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, count as data_eventcount" . " | eval data_name=\"" . data_name . "\", data_last_ingestion_lag_seen=data_last_ingest-data_last_time_seen",\
search_mode="mstats", "| " . search_mode . " latest(_value) as value" . " where " . search_constraint . " by metric_name span=1s | stats min(_time) as data_first_time_seen, max(_time) as data_last_time_seen, dc(metric_name) as data_eventcount | eval data_name=\"" . data_name . "\", data_last_ingest=data_last_time_seen, data_last_ingestion_lag_seen=now()-data_last_time_seen"\
)
iseval = 0

# used to simulate elastic sources
[trackme_elastic_sources_simulate]
definition = rex field=search_constraint "^(?<from_part1>[^\|]*)\|(?<from_part2>.*)"\
| `trackme_eval_spl` | fields spl | eval prefix="| append [ ", eval suffix=" ]"\
| streamstats count as line_count\
| eval spl = if(line_count!=1, prefix . spl . suffix, spl)\
| fields spl\
| stats list(spl) AS spl\
| eval spl=mvjoin(spl, " ")\
| append [ | makeresults | eval spl=if(isnull(spl), "| makeresults", spl) | fields - _time ] | head 1 ]\
| where isnotnull(data_name) AND data_eventcount>0\
`comment("#### The macro expects a different name for the first time seen ####")`\
| rename data_first_time_seen as current_data_first_time_seen\
| eval data_index=if(isnull(elastic_data_index) OR elastic_data_index="none", data_name, elastic_data_index)\
| eval data_sourcetype=if(isnull(elastic_data_sourcetype) OR elastic_data_index="none", data_name, elastic_data_sourcetype)\
`trackme_data_source_tracker_abstract`\
| append [ | makeresults | eval simulation_results="No results found, please verify your search." | fields - _time ]\
| fillnull value="Success, click on save on add this elastic source." simulation_results\
| lookup trackme_elastic_sources data_name OUTPUT data_name as data_name_found\
| eval simulation_results=if(isnotnull(data_name_found), "ERROR: this data_source was found in the collection!", simulation_results)\
| eval " " = case(\
simulation_results="No results found, please verify your search.", "icon|ico_warn ico_small|icon-close|no results",\
simulation_results="ERROR: this data_source was found in the collection!", "icon|ico_error ico_small|icon-close|error",\
simulation_results="Success, click on save on add this elastic source.", "icon|ico_good ico_small|icon-check|success")\
| fields " ", simulation_results, data_name, data*, *\
| head 1

# used within the UI to get search definition for elastic sources
[trackme_lookup_elastic_sources]
definition = lookup trackme_elastic_sources data_name OUTPUT search_constraint as elastic_source_search_constraint, search_mode as elastic_source_search_mode\
| rex field=elastic_source_search_constraint "^(?<elastic_source_from_part1>[^\|]*)\|(?<elastic_source_from_part2>.*)"
iseval = 0
